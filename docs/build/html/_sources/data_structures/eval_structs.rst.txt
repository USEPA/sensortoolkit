Performance Evaluation Data Structures
--------------------------------------

.. role:: raw-html(raw)
   :format: html

Various data structures containing tabular statistics and information about
evaluation conditions can also be constructed. These data structures can be
constructed by running the following line of code:

.. code-block:: python

  evaluation.calculate_metrics()

This will construct the statistics dataframes ``evaluation.stats_df`` and ``evaluation.avg_stats_df`` and
populate the deployment dictionary ``evaluation.deploy_dict`` with details about the evaluation.
More detail about each of these data structures is provided below.

Statistics DataFrames
^^^^^^^^^^^^^^^^^^^^^

Sensor vs. FRM/FEM Statistics: ``evaluation.stats_df``
""""""""""""""""""""""""""""""""""""""""""""""""""""""

A pandas DataFrame containing statistics for the sensor vs. FRM/FEM linearity (:raw-html:`R<sup>2</sup>`),
bias (slope and intercept), RMSE, N (number of sensor-FRM/FEM data point pairs), as well
as the minimum, maximum, and the mean sensor concentration. Data are presented for all
averaging intervals specified by ``evaluation.eval_param_averaging``.

``evaluation.stats_df`` is saved as a comma-separated value file at
``/data/eval_stats/[sensor_name]/[sensor_name]_[parameter]_vs_[reference_name]_stats_df_YYMMDD.csv``

where ``[sensor_name]`` is the name of the sensor, ``[parameter]`` is the SDFS parameter name,
``[reference_name]`` is the name of the reference monitor, and ``YYMMDD`` is the date the figure was compiled.

Below is an example of ``evaluation.stats_df`` for the ``Example_Make_Model`` sensor dataset:

.. csv-table:: `stats_df.csv`
   :file: ../data/stats_df.csv
   :header-rows: 1
   :widths: auto

Sensor vs. Intersensor Average Statistics: ``evaluation.avg_stats_df``
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

A pandas DataFrame containing statistics relating the sensor vs. intersensor average
linearity (:raw-html:`R<sup>2</sup>`), bias (slope and intercept), RMSE, N (number of concurrent
sensor measurements during which all sensors in the testing group reported values), as well as the
minimum, maximum, and the mean sensor concentration. Data are presented for all
averaging intervals specified by ``evaluation.eval_param_averaging``.

``evaluation.avg_stats_df`` is saved as a comma-separated value file at
``/data/eval_stats/[sensor_name]/[sensor_name]_[parameter]_vs_[reference_name]_avg_stats_df_YYMMDD.csv``

where ``[sensor_name]`` is the name of the sensor, ``[parameter]`` is the SDFS parameter name,
``[reference_name]`` is the name of the reference monitor, and ``YYMMDD`` is the date the figure was compiled.

Below is an example of ``evaluation.stats_df`` for the ``Example_Make_Model`` sensor dataset:

.. csv-table:: `avg_stats_df.csv`
   :file: ../data/avg_stats_df.csv
   :header-rows: 1
   :widths: auto

Deployment Dictionary: ``evaluation.deploy_dict``
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The deployment dictionary ``evaluation.deploy_dict`` contains descriptive statistics and textual information about
the deployment, including details about the testing agency, deployment site,
sensors tested, and site conditions during the evaluation.

The top level organizes details by deployment group, testing information, and
testing location. A deployment group is defined as a collection of sensors that are
collocated and concurrently recording data during a consecutive timeframe.

Expanding the deployment group field, three subfields are listed detailing sensor
descriptions (`sensors`), statistics pertaining to the evaluation parameter (`PM25`),
and statistics describing the meteorological site conditions during the deployment
(`Meteorological Conditions`). Timestamps for the start, end, and duration of the
evaluation are also listed (derived from sensor dataset timestamps).

The parameter statistics subfield contains categories for sensor-sensor (inter-sensor)
precision, error relative to FRM/FEM, and reference (FRM/FEM) measurement statistics.
The example shown below is for a scenario where the evaluation parameter is ``PM25``
(:raw-html:`PM<sub>2.5</sub>`). Statistics are presented at sampling frequencies indicated for the
evaluation parameter via the  eval_param_averaging instance attribute.

The Meteorological Conditions subfield contains statistics pertaining to
temperature, relative humidity, and other parameters measured by instruments
at the testing site. These measurements are independent of air sensor meteorological
measurements collected by internal sensing components.

The deployment dictionary ``evaluation.deploy_dict`` is saved as a JSON file to
``/data/eval_stats/[sensor_name]/[sensor_name]_[parameter]_Evaluation_YYMMDD.json``

where ``[sensor_name]`` is the name of the sensor, ``[parameter]`` is the SDFS parameter name,
``[reference_name]`` is the name of the reference monitor, and ``YYMMDD`` is the date the figure was compiled.

Below is an example of ``evaluation.deploy_dict`` for the ``Example_Make_Model`` sensor dataset:

.. code-block:: json

  {
      "sensortoolkit Version": "1.0.0",
      "Date of Analysis": "2021-08-25 09:46:19 AM",
      "Testing Organization": {
          "Deployment number": "Deployment #1",
          "Org name": [
              "U.S. Environmental Protection Agency",
              "Office of Research and Development"
          ],
          "Website": {
              "website name": "Air Sensor Toolbox | U.S. EPA Website",
              "website link": "https://www.epa.gov/air-sensor-toolbox/evaluation-emerging-air-sensor-performance"
          },
          "Contact email": "PI: Clements.Andrea@epa.gov",
          "Contact phone": "919-541-1364"
      },
      "Testing Location": {
          "Site name": "Ambient Monitoring Innovative Research Station (AIRS) ",
          "Site address": "Research Triangle Park, NC",
          "Site lat": "35.889510N",
          "Site long": "-78.874572W",
          "Site AQS ID": "37 \u2013 063 \u2013 0099"
      },
      "Sensor Name": "Example_Make_Model",
      "Deployment Groups": {
          "Group 1": {
              "eval_start": "2019-08-01 12:11:00",
              "eval_end": "2019-09-02 04:59:00",
              "eval_duration": "31 days 16:48:00",
              "sensors": {
                  "1": {
                      "serial_id": "SN01",
                      "deploy_issues": "False",
                      "recording_interval": "1.0 minute",
                      "uptime_1-hour": 97.368,
                      "uptime_24-hour": 93.75
                  },
                  "2": {
                      "serial_id": "SN02",
                      "deploy_issues": "False",
                      "recording_interval": "1.0 minute",
                      "uptime_1-hour": 97.632,
                      "uptime_24-hour": 93.75
                  },
                  "3": {
                      "serial_id": "SN03",
                      "deploy_issues": "False",
                      "recording_interval": "1.0 minute",
                      "uptime_1-hour": 97.632,
                      "uptime_24-hour": 93.75
                  }
              },
              "PM25": {
                  "Precision": {
                      "cv_1-hour": 13.094,
                      "std_1-hour": 0.581,
                      "n_1-hour": 736,
                      "cv_24-hour": 7.091,
                      "std_24-hour": 0.313,
                      "n_24-hour": 30
                  },
                  "Error": {
                      "rmse_1-hour": 3.798,
                      "nrmse_1-hour": 48.561,
                      "rmse_24-hour": 3.615,
                      "nrmse_24-hour": 46.804
                  },
                  "Reference": {
                      "reference_name": "Teledyne API T640x",
                      "conc_min_1-hour": 3.352,
                      "conc_max_1-hour": 15.318,
                      "n_exceed_conc_goal_1-hour": 0,
                      "conc_min_24-hour": 4.999,
                      "conc_max_24-hour": 11.087,
                      "n_exceed_conc_goal_24-hour": 0
                  }
              },
              "Meteorological Conditions": {
                  "Temperature": {
                      "instrument_name": "RM Young 41382 VC",
                      "min_1-hour": 14.348,
                      "max_1-hour": 37.735,
                      "n_exceed_target_criteria_1-hour": 0,
                      "n_measurement_pairs_1-hour": 758.0,
                      "min_24-hour": 21.21,
                      "max_24-hour": 28.956,
                      "n_exceed_target_criteria_24-hour": 0,
                      "n_measurement_pairs_24-hour": 32.0
                  },
                  "Relative Humidity": {
                      "instrument_name": "RM Young 41382 VC",
                      "min_1-hour": 24.933,
                      "max_1-hour": 97.0,
                      "n_exceed_target_criteria_1-hour": 172,
                      "n_measurement_pairs_1-hour": 758.0,
                      "min_24-hour": 60.369,
                      "max_24-hour": 88.171,
                      "n_exceed_target_criteria_24-hour": 0,
                      "n_measurement_pairs_24-hour": 32.0
                  }
              }
          }
      }
  }

.. note::
  ``n_exceed_conc_goal`` (1-hour/24-hour) for the evaluation parameter reference
  is the number of averaging intervals during which the reference concentration
  exceeds the EPA’s recommended elevated concentration value for either :raw-html:`PM<sub>2.5</sub>`
  (>25 :raw-html:`μg/m<sup>3</sup>`) or :raw-html:`O<sub>3</sub>` (> 60 ppbv) testing.

  This term as it relates to the ``Meteorological_Conditions`` subcategories for
  temperature and relative humidity indicate the number of intervals during which
  conditions exceeded the manufacturer's recommended operating range.
